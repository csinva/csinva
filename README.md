<p>
  <pre align="center">
Hi there ðŸ‘‹ I'm Chandan, a Senior Researcher at Microsoft Research working on interpretable machine learning.
<a href="https://csinva.io/">Homepage</a> / <a href="https://twitter.com/csinva">Twitter</a> / <a href="https://scholar.google.com/citations?hl=en&user=XpttKK8AAAAJ&view_op=list_works&sortby=pubdate">Google Scholar</a> / <a href="https://www.linkedin.com/in/csinva/">LinkedIn</a> </pre>
</p>

## ðŸŒ³ Interpretable models / dataset explanations

<a href="https://github.com/csinva/imodels"><img align="center" style="height:30px;" src="https://csinva.io/imodels/img/imodels_logo.svg?sanitize=True"> </img></a> **![](https://img.shields.io/github/stars/csinva/imodels?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Interpretable and accurate predictive modeling, sklearn-compatible ([JOSS 2021](https://joss.theoj.org/papers/10.21105/joss.03192)), Contains FIGS ([arXiv 2022](https://arxiv.org/abs/2201.11931)) and HSTree ([ICML 2022](https://arxiv.org/abs/2202.00858))

<a href="https://github.com/csinva/imodelsX"><img align="center" style="height:35px;" src="https://csinva.io/imodelsX/imodelsx_logo.svg?sanitize=True"> </img></a> **![](https://img.shields.io/github/stars/csinva/imodelsX?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Interpretability for text. Contains Aug-imodels ([Nature Communications 2023](https://arxiv.org/abs/2209.11799)) ![](https://img.shields.io/github/stars/microsoft/augmented-interpretable-models?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), iPrompt ([ICLR workshop 2023](https://arxiv.org/abs/2210.01848)) ![](https://img.shields.io/github/stars/csinva/interpretable-autoprompting?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), SASC ([arXiv 2023](https://arxiv.org/abs/2305.09863)) ![](https://img.shields.io/github/stars/microsoft/automated-explanations?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), and Tree-Prompt ([EMNLP 2023](https://arxiv.org/abs/2310.14034)) ![](https://img.shields.io/github/stars/csinva/tree-prompt?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)

**[adaptive-wavelets](https://github.com/Yu-Group/adaptive-wavelet-distillation) ![](https://img.shields.io/github/stars/Yu-Group/adaptive-wavelet-distillation?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Adaptive, interpretable wavelets across domains ([NeurIPS 2021](https://arxiv.org/abs/2107.09145))

## ðŸ¤– General-purpose AI packages and cheatsheets

<a href="https://github.com/csinva/csinva.github.io"><img align="center" style="height:30px;" src="https://csinva.io/blog/compiled_notes/_build/html//_static/logo.png"> </img></a> **![](https://img.shields.io/github/stars/csinva/csinva.github.io?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Notes and resources on AI

<a href="https://github.com/Yu-Group/veridical-flow"><img align="center" style="height:30px;" src="https://yu-group.github.io/veridical-flow/logo_vflow_straight.png"> </img></a> **![](https://img.shields.io/github/stars/Yu-Group/pcs-pipeline?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Utilities for trustworthy data-science ([JOSS 2021](https://joss.theoj.org/papers/10.21105/joss.03895))

## ðŸ§  Interpreting neural networks

**[deep-explanation-penalization](https://github.com/laura-rieger/deep-explanation-penalization) ![](https://img.shields.io/github/stars/laura-rieger/deep-explanation-penalization?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Penalizing neural-network explanations ([ICML 2020](https://arxiv.org/abs/1909.13584))

**[hierarchical-dnn-interpretations](https://github.com/csinva/hierarchical-dnn-interpretations) ![](https://img.shields.io/github/stars/csinva/hierarchical-dnn-interpretations?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Hierarchical interpretations for neural network predictions ([ICLR 2019](https://arxiv.org/abs/1806.05337))

**[transformation-importance](https://github.com/csinva/transformation-importance) ![](https://img.shields.io/github/stars/csinva/transformation-importance?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Transformation Importance with Applications to Cosmology ([ICLR Workshop 2020](https://arxiv.org/abs/2003.01926))


## ðŸ“Š Data-science problems

**[covid19-severity-prediction](https://github.com/Yu-Group/covid19-severity-prediction) ![](https://img.shields.io/github/stars/Yu-Group/covid19-severity-prediction?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Extensive and accessible COVID-19 data + forecasting for counties and hospitals ([HDSR 2021](https://hdsr.mitpress.mit.edu/pub/p6isyf0g/release/4))

**[clinical-rule-vetting](https://github.com/Yu-Group/rule-stress-testing) ![](https://img.shields.io/github/stars/Yu-Group/rule-stress-testing?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** General pipeline for deriving clinical decision rules

**[iai-clinical-decision-rule](https://github.com/csinva/iai-clinical-decision-rule) ![](https://img.shields.io/github/stars/csinva/iai-clinical-decision-rule?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Interpretable clinical decision rules for predicting intra-abdominal injury ([PLOS Digital Health 2022](https://journals.plos.org/digitalhealth/article?id=10.1371/journal.pdig.0000076))

**[molecular-partner-prediction](https://github.com/Yu-Group/molecular-partner-prediction) ![](https://img.shields.io/github/stars/csinva/auxilin-prediction?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Predicting successful CME events using only clathrin markers


## Various aspects of deep learning and machine learning

**[gan-vae-pretrained-pytorch](https://github.com/csinva/gan-vae-pretrained-pytorch) ![](https://img.shields.io/github/stars/csinva/gan-vae-pretrained-pytorch?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Pretrained GANs + VAEs + classifiers for MNIST/CIFAR in pytorch

**[gpt2-paper-title-generator](https://github.com/csinva/gpt2-paper-title-generator) ![](https://img.shields.io/github/stars/csinva/gpt2-paper-title-generator?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Generating paper titles with GPT-2

**[disentangled-attribution-curves](https://github.com/csinva/disentangled-attribution-curves) ![](https://img.shields.io/github/stars/csinva/disentangled-attribution-curves?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Disentangled Attribution Curves for Interpreting Random Forests and Boosted Trees ([arxiv 2019](https://arxiv.org/abs/1905.07631))

**[matching-with-gans](https://github.com/csinva/matching-with-gans) ![](https://img.shields.io/github/stars/csinva/matching-with-gans?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Matching in GAN latent space for better bias benchmarking. ([CVPR workshop 2021](https://arxiv.org/abs/2103.13455))

**[data-viz-utils](https://github.com/csinva/data-viz-utils) ![](https://img.shields.io/github/stars/csinva/data-viz-utils?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Functions for easily making publication-quality figures with matplotlib

**[mdl-complexity](https://github.com/csinva/mdl-complexity) ![](https://img.shields.io/github/stars/csinva/mdl-complexity?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Revisiting complexity and the bias-variance tradeoff ([TOPML workshop 2021](https://arxiv.org/abs/2006.10189))

## Projects advised

**[pasta](https://github.com/QingruZhang/PASTA) ![](https://img.shields.io/github/stars/QingruZhang/PASTA?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)** Tell Your Model Where to Attend: Post-hoc Attention Steering for LLMs ([NeurIPS workshop 2023](https://arxiv.org/abs/2311.02262))

## Open-source contributions

Major: **[autogluon](https://github.com/awslabs/autogluon) ![](https://img.shields.io/github/stars/awslabs/autogluon?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [big-bench](https://github.com/google/BIG-bench) ![](https://img.shields.io/github/stars/google/BIG-bench?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [nl-augmenter](https://github.com/GEM-benchmark/NL-Augmenter) ![](https://img.shields.io/github/stars/GEM-benchmark/NL-Augmenter?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)**

Minor: **[conference-acceptance-rates](https://github.com/lixin4ever/Conference-Acceptance-Rate) ![](https://img.shields.io/github/stars/lixin4ever/Conference-Acceptance-Rate?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [iterative-random-forest](https://github.com/Yu-Group/iterative-Random-Forest) ![](https://img.shields.io/github/stars/Yu-Group/iterative-Random-Forest?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [interpretable-ml-book](https://github.com/christophM/interpretable-ml-book) ![](https://img.shields.io/github/stars/christophM/interpretable-ml-book?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [awesome-interpretable-machine-learning](https://github.com/lopusz/awesome-interpretable-machine-learning) ![](https://img.shields.io/github/stars/lopusz/awesome-interpretable-machine-learning?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [awesome-machine-learning-interpretability](https://github.com/jphall663/awesome-machine-learning-interpretability) ![](https://img.shields.io/github/stars/jphall663/awesome-machine-learning-interpretability?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [awesome-llm-interpretability](https://github.com/JShollaj/awesome-llm-interpretability) ![](https://img.shields.io/github/stars/JShollaj/awesome-llm-interpretability?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [executable-books](https://github.com/executablebooks/meta) ![](https://img.shields.io/github/stars/executablebooks/meta?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE), [deep-fMRI-dataset](https://github.com/HuthLab/deep-fMRI-dataset) ![](https://img.shields.io/github/stars/HuthLab/deep-fMRI-dataset?color=%23EEE&style=flat-square&label=%E2%AD%90&labelColor=%23EEE)**

## Mini-projects

**[hummingbird-tracking](https://github.com/csinva/hummingbird-tracking), [imodels-experiments](https://github.com/Yu-Group/imodels-experiments), [cookiecutter-ml-research](https://github.com/csinva/cookiecutter-ml-research), [nano-descriptions](https://github.com/csinva/nano-descriptions), [news-title-bias](https://github.com/csinva/news-title-bias), [java-mini-games](https://github.com/csinva/mini-games), [imodels-data](https://github.com/csinva/imodels-data), [news-balancer](https://github.com/csinva/news-balancer), [arxiv-copier](https://github.com/csinva/arxiv-copier), [dnn-experiments](https://github.com/csinva/dnn-experiments), [max-activation-interpretation-pytorch](https://github.com/csinva/max-activation-interpretation-pytorch), [acronym-generator](https://github.com/csinva/acronym-generator), [hpa-interp](https://github.com/csinva/hpa-interp), [sensible-local-interpretations](https://github.com/csinva/sensible-local-interpretations), [global-sports-analysis](https://github.com/csinva/global-sports-analysis), [mouse-brain-decoding](https://github.com/csinva/mouse-brain-decoding),  ...**
